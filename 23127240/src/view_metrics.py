#!/usr/bin/env python3
"""
Script hiá»ƒn thá»‹ metrics realtime - cháº¡y song song vá»›i scraper
"""

import os
import sys
import json
import pandas as pd
from datetime import datetime
import time

def clear_screen():
    os.system('clear' if os.name == 'posix' else 'cls')

def display_metrics(data_dir="23127240_data"):
    """Hiá»ƒn thá»‹ metrics tá»« cÃ¡c file CSV/JSON"""
    
    details_csv = os.path.join(data_dir, "paper_details.csv")
    stats_csv = os.path.join(data_dir, "scraping_stats.csv")
    stats_json = os.path.join(data_dir, "scraping_stats.json")
    
    clear_screen()
    
    print("="*80)
    print(f"ğŸ“Š ARXIV SCRAPER - REALTIME METRICS")
    print(f"â° Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    print()
    
    # Check paper details
    if os.path.exists(details_csv):
        try:
            df = pd.read_csv(details_csv)
            total_papers = len(df)
            
            print(f"âœ… Papers Processed: {total_papers}")
            print()
            print("ğŸ“ˆ Performance Metrics:")
            print(f"   Avg runtime: {df['runtime_s'].mean():.2f}s per paper")
            print(f"   Avg size after: {df['size_after'].mean()/1024:.2f} KB")
            print(f"   Avg references: {df['num_refs'].mean():.2f}")
            print(f"   Max RAM: {df['max_rss'].max():.2f} MB")
            print(f"   Current RAM: {df['avg_rss'].iloc[-1]:.2f} MB")
            print()
            
            print("ğŸ“‹ Last 5 Papers:")
            print("-"*80)
            last_5 = df[['paper_id', 'arxiv_id', 'runtime_s', 'num_refs']].tail(5)
            for _, row in last_5.iterrows():
                print(f"   [{row['paper_id']:4d}] {row['arxiv_id']:15s} | {row['runtime_s']:6.2f}s | {row['num_refs']:2.0f} refs")
            print("-"*80)
            print()
            
            print(f"â±ï¸  Last Update: {df.iloc[-1]['processed_at']}")
            
        except Exception as e:
            print(f"âŒ Error reading paper_details.csv: {e}")
    else:
        print("â³ Waiting for first checkpoint (50 papers)...")
        print("   paper_details.csv will be created after 50 papers")
    
    print()
    
    # Check stats JSON
    if os.path.exists(stats_json):
        try:
            with open(stats_json, 'r') as f:
                stats = json.load(f)
            
            data_stats = stats.get('data_statistics', {})
            perf_time = stats.get('performance_running_time', {})
            perf_mem = stats.get('performance_memory_footprint', {})
            
            print("ğŸ“Š Summary Statistics:")
            print(f"   Success rate: {data_stats.get('success_rate', 0):.2f}%")
            print(f"   Total runtime: {perf_time.get('total_runtime_s', 0)/60:.2f} minutes")
            print(f"   Disk usage: {perf_mem.get('max_disk_mb', 0):.2f} MB")
            
        except Exception as e:
            print(f"âŒ Error reading stats: {e}")
    
    print()
    print("="*80)
    print("ğŸ’¡ Press Ctrl+C to exit | Updates every 30s")
    print("="*80)

def main():
    """Main loop - cáº­p nháº­t má»—i 30 giÃ¢y"""
    
    # Kiá»ƒm tra thÆ° má»¥c data
    data_dir = "23127240_data"
    if not os.path.exists(data_dir):
        # Thá»­ tÃ¬m trong parent directory
        data_dir = "../23127240_data"
        if not os.path.exists(data_dir):
            print(f"âŒ Error: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c {data_dir}")
            print("   Cháº¡y script nÃ y tá»« thÆ° má»¥c chá»©a '23127240_data' hoáº·c tá»« 'src/'")
            sys.exit(1)
    
    print("ğŸš€ Starting metrics viewer...")
    print("   Monitoring:", os.path.abspath(data_dir))
    time.sleep(2)
    
    try:
        while True:
            display_metrics(data_dir)
            time.sleep(30)  # Cáº­p nháº­t má»—i 30 giÃ¢y
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Exiting metrics viewer...")
        sys.exit(0)

if __name__ == "__main__":
    main()
